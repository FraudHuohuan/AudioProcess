import streamlit as st
import requests
import numpy as np
import soundfile as sf
import os

proxy_address = "127.0.0.1:7890"
os.environ["http_proxy"] = proxy_address
os.environ["https_proxy"] = proxy_address

# å…¨å±€å˜é‡å­˜å‚¨è¯­éŸ³æ•°æ®
audio_data = None

# è¯­éŸ³è¯†åˆ«
def recognize_speech(audio_file):
    API_URL = "https://api-inference.huggingface.co/models/openai/whisper-large-v3"
    headers = {"Authorization": "Bearer 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"}

    def recognize(filename):
        with open(filename, "rb") as f:
            data = f.read()
        response = requests.post(API_URL, headers=headers, data=data)
        return response.json()

    output = recognize(audio_file)
    return output

# å½•éŸ³å‡½æ•°
def record_audio(sample_rate=16000):
    st.write("è¯·å¼€å§‹è¯´è¯ï¼Œå½•éŸ³å°†æŒç»­ç›´åˆ°æ‚¨ç‚¹å‡»åœæ­¢...")
    audio_data = sf.audio_recorder(sampling_rate=sample_rate, duration=record_seconds, codec='wav')
    st.write("å½•éŸ³è¿›è¡Œä¸­...")
    return audio_data

# ä¿å­˜å½•éŸ³æ•°æ®åˆ°WAVæ–‡ä»¶
def save_audio(filename):
    global audio_data
    # ä¿å­˜å½•éŸ³æ•°æ®åˆ°WAVæ–‡ä»¶
    sf.write(filename, audio_data, 44100, subtype='PCM_16')

# æ˜¾ç¤ºå½•éŸ³æ•°æ®
def display_audio(filename):
    audio_data_saved = np.array(sf.read(filename)[0])
    st.audio(audio_data_saved, format='audio/wav', sample_rate=44100)

# éŸ³é¢‘ä¸Šä¼ å‡½æ•°
def upload_audio():
    global audio_data

    uploaded_file = st.file_uploader("ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼ˆè¦†ç›–æ—§çš„å½•éŸ³ï¼‰", type=["wav", "mp3"])
    if uploaded_file is not None:
        # ä¿å­˜ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶
        with open("uploaded_audio.wav", "wb") as f:
            f.write(uploaded_file.getvalue())

        # è¯»å–ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶å¹¶ä¿å­˜åˆ°audio_data
        audio_data, _ = sf.read("uploaded_audio.wav")

# Streamlit App
st.title("ğŸ™ï¸ Speech Recognition")


# é€‰æ‹©å½•éŸ³æˆ–ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
choice = st.radio("è¯·é€‰æ‹©å½•éŸ³æ–¹å¼", ("å½•éŸ³", "ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"))
# å¦‚æœé€‰æ‹©å½•éŸ³
if choice == "å½•éŸ³":
   seconds_to_record = st.slider("å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰", min_value=1, max_value=10, value=3)
   if st.button("å¼€å§‹å½•éŸ³"):
       # æ‰§è¡Œå½•éŸ³æ“ä½œ
       record_audio(seconds_to_record)       
# å¦‚æœé€‰æ‹©ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
elif choice == "ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶":
   upload_audio()

if audio_data is not None:
  save_audio("output.wav")
  display_audio("output.wav")
  st.write("æ­£åœ¨è¯†åˆ«è¯­éŸ³ï¼Œè¯·ç¨å€™...")
  recognition_result = recognize_speech("output.wav")
  st.write("è¯†åˆ«ç»“æœï¼š", recognition_result["text"])
